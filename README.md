# Consistency-aware Fake Videos Detection on Short Video Platforms


## ğŸ“¦ Dataset Preparation

Due to copyright reasons, we are unable to provide the original datasets.  You can download them from the following links:

### FakeSV

- **Description**: A multimodal benchmark for fake news detection on short video platforms.
- **Access**: [ICTMCG/FakeSV](https://github.com/ICTMCG/FakeSV)  
  ğŸ“„ *FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News Detection on Short Video Platforms*, AAAI 2023.

### FakeTT

- **Description**: A dataset for fake news detection from the perspective of creative manipulation.
- **Access**: [ICTMCG/FakingRecipe](https://github.com/ICTMCG/FakingRecipe)  
  ğŸ“„ *FakingRecipe: Detecting Fake News on Short Video Platforms from the Perspective of Creative Process*, ACM MM 2024.

---

## ğŸ› ï¸ Prepare

### ğŸ“‚ Feature Acquisition

You can obtain the original feature files from the following link:

- **features**: [Download from FakingRecipe repository](https://github.com/ICTMCG/FakingRecipe)


### ğŸ“ Pseudo Labels Preparation

You should insert the pseudo labels from the *pseudo_label* folder into the corresponding *metainfo.json* files based on the video IDs.

- *pseudo_label*: Folder containing the generated pseudo labels for each video.
- *metainfo.json*: Metadata file where you need to add the pseudo label information for each video.


- ### ğŸ—‚ï¸ Code Structure

The overall structure of this project is organized as follows:

```text
CA_FVD/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ FakeSV/
â”‚   â”‚   â””â”€â”€ data-split/              # Video ID splits for training/validation/testing
â”‚   â”œâ”€â”€ FakeTT/
â”‚   â”‚   â””â”€â”€ data-split/              # Video ID splits for generalization test
â”œâ”€â”€ fea/                             # Extracted features
â”‚   â”œâ”€â”€ fakesv/
â”‚   â”‚   â”œâ”€â”€ preprocess_audio/        # Audio features
â”‚   â”‚   â”œâ”€â”€ preprocess_text/         # Text features
â”‚   â”‚   â”œâ”€â”€ preprocess_visual/       # Visual features
â”‚   â”‚   â”œâ”€â”€ fakesv_segment_duration.json
â”‚   â”‚   â””â”€â”€ metainfo.json
â”‚   â”œâ”€â”€ fakett/
â”‚   â”‚   â”œâ”€â”€ preprocess_audio/
â”‚   â”‚   â”œâ”€â”€ preprocess_text/
â”‚   â”‚   â”œâ”€â”€ preprocess_visual/
â”‚   â”‚   â”œâ”€â”€ fakett_segment_duration.json
â”‚   â”‚   â””â”€â”€ metainfo.json
â”œâ”€â”€ dataloader/
â”‚   â””â”€â”€ dataloader.py                # Code for loading datasets
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ attention.py                 # Attention modules
â”‚   â”œâ”€â”€ CA_FVD.py                    # Main model definition
â”‚   â”œâ”€â”€ transformer_align.py         # Transformer-based alignment modules
â”‚   â””â”€â”€ trm.py                       # Temporal relation modeling
â”œâ”€â”€ pseudo_label/                    # Folder containing pseudo labels
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ metrics.py                   # Evaluation metrics
â”‚   â”œâ”€â”€ Trainer.py                   # Training management code
â”œâ”€â”€ main.py                          # Entry point for training
â”œâ”€â”€ requirements.txt                 # Python dependency list
â”œâ”€â”€ run.py                           # Entry point for inference
text```

---

## âš™ï¸ Environment Setup and Run

You can set up the environment by running the following commands:

```bash
# 1. Create a new conda environment named CA_FVD
conda create -n CA_FVD python=3.10.16

# 2. Activate the environment
conda activate CA_FVD

# 3. Install PyTorch 2.0.1 with CUDA 11.7 support
pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117 torchaudio==2.0.2+cu117 --extra-index-url https://download.pytorch.org/whl/cu117

# 4. Install the remaining dependencies
pip install -r requirements.txt

# 5. run
python main.py

